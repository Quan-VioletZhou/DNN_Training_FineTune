{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the words with filtering by the 587 in Kell et al., paper \n",
    "# It will only generate ~7000 ish \n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def load_ids_and_words(csv_file):\n",
    "    df = pd.read_csv(csv_file, header=None) \n",
    "    file_ids = pd.unique(df.iloc[:, 2:].values.ravel('K'))\n",
    "    file_ids = [x for x in file_ids if str(x) != 'nan']\n",
    "    target_words = df.iloc[:, 0].tolist()\n",
    "    return file_ids, target_words\n",
    "\n",
    "def find_audio_files(root_path, file_ids):\n",
    "    \"\"\"\n",
    "    Perform an exhaustive search for all occurrences of specified file IDs.\n",
    "\n",
    "    :param root_path: The root directory where TRAIN and TEST are stored.\n",
    "    :param file_ids: A set of file IDs to search for.\n",
    "    :return: A dictionary where each file ID maps to a list of matching file paths.\n",
    "    \"\"\"\n",
    "    found_files = {file_id: [] for file_id in file_ids}\n",
    "\n",
    "    # Walk through all subdirectories (TRAIN, TEST, DR1-DR8, Speaker Folders)\n",
    "    for root, _, files in os.walk(root_path):\n",
    "        file_set = set(files)  # Convert to set for faster lookup\n",
    "        \n",
    "        for file in files:\n",
    "            file_id = file.split('.')[0]  # Extract file ID before the extension\n",
    "\n",
    "            # Check if the file is a .WAV file and its ID is in the search list\n",
    "            if file_id in file_ids and file.endswith('.WAV'):\n",
    "                # print(file_id)\n",
    "                corresponding_wrd = file_id + '.WRD'\n",
    "                # print(corresponding_wrd)\n",
    "\n",
    "                # Ensure the corresponding .WRD file exists\n",
    "                if corresponding_wrd in file_set:\n",
    "                    found_files[file_id].append(os.path.join(root, file))\n",
    "\n",
    "    # Remove entries that were not found at all\n",
    "    found_files = {key: val for key, val in found_files.items() if val}\n",
    "\n",
    "    return found_files\n",
    "\n",
    "\n",
    "\n",
    "def extract_audio_clip(wrd_file, wav_file, target_word, output_folder):\n",
    "    try:\n",
    "        with open(wrd_file, 'r', encoding='latin1') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 3 and parts[2] == target_word:\n",
    "                    start_sample = int(parts[0])\n",
    "                    end_sample = int(parts[1])\n",
    "                    break\n",
    "            else:\n",
    "                return None  # Target word not found\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Encoding error in reading the WRD file\")\n",
    "        return None\n",
    "\n",
    "    # Convert sample points to seconds (assuming 16000 Hz sample rate)\n",
    "    start_sec = start_sample / 16000\n",
    "    end_sec = end_sample / 16000\n",
    "\n",
    "    # Add 100ms padding before and after the word\n",
    "    padding = 0.1  # 100 milliseconds\n",
    "    start_sec = max(0, start_sec - padding)  # Ensure start_sec is not negative\n",
    "\n",
    "    # Fetch the total duration of the audio file to ensure end_sec does not exceed it\n",
    "    try:\n",
    "        result = subprocess.run(['sox', '--i', '-D', wav_file], text=True, capture_output=True, check=True)\n",
    "        total_duration_sec = float(result.stdout.strip())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to get duration of audio file. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    end_sec = min(end_sec + padding, total_duration_sec)  # Ensure end_sec does not exceed the audio length\n",
    "    duration_sec = end_sec - start_sec\n",
    "\n",
    "    # Construct the output file path\n",
    "    folder_name = os.path.basename(os.path.dirname(wav_file))\n",
    "    output_filename = f\"{target_word}_{folder_name}_{os.path.basename(wav_file)}\"\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    # Build sox command to trim the audio\n",
    "    command = [\n",
    "        'sox', wav_file, output_path, 'trim', str(start_sec), str(duration_sec)\n",
    "    ]\n",
    "\n",
    "    # Execute sox command\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Successfully extracted {output_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to extract audio segment. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    return output_path\n",
    "\n",
    "# Parameters\n",
    "csv_file_path = 'D:\\\\DNN\\\\Training_data\\\\TIMIT\\\\high_freq_words.csv'\n",
    "base_path = 'D:\\\\DNN\\\\Training_data\\\\TIMIT\\\\raw\\\\timit\\\\data'  # Updated base path\n",
    "output_folder = 'D:\\\\DNN\\\\Training_data\\\\TIMIT\\\\Extracted_Clips_new'\n",
    "\n",
    "# Load file IDs and target words from CSV\n",
    "file_ids, target_words = load_ids_and_words(csv_file_path)\n",
    "\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Find and process files\n",
    "found_files = find_audio_files(base_path, file_ids)\n",
    "print(found_files)\n",
    "\n",
    "for file_id, paths in found_files.items():\n",
    "    for path in paths:\n",
    "        wrd_file = path.replace('.WAV', '.WRD')\n",
    "        print(wrd_file)\n",
    "        if os.path.exists(wrd_file):\n",
    "            for target_word in target_words:\n",
    "                extracted_clip_path = extract_audio_clip(wrd_file, path, target_word, output_folder)\n",
    "                if extracted_clip_path:\n",
    "                    print(f\"Extracted clip saved as: {extracted_clip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# Define paths\n",
    "root_dir = \"D:\\\\DNN\\\\Training_data\\\\TIMIT\\\\raw\\\\timit\\\\data\"  # Change this to your actual data folder\n",
    "output_audio_dir = \"D:\\\\DNN\\\\Training_data\\\\TIMIT\\\\Extracted_Clips_all_words\"  # Folder for extracted clips\n",
    "os.makedirs(output_audio_dir, exist_ok=True)\n",
    "\n",
    "# Dictionary to count word occurrences\n",
    "word_counts = {}\n",
    "\n",
    "# Loop through all WRD files in the directory recursively\n",
    "for root, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.WRD'):\n",
    "            wrd_file = os.path.join(root, file)\n",
    "            wav_file = wrd_file.replace('.WRD', '.WAV')\n",
    "\n",
    "            if os.path.exists(wav_file):\n",
    "                with open(wrd_file, \"r\", encoding=\"latin1\") as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 3:\n",
    "                            start_sample, end_sample, word = int(parts[0]), int(parts[1]), parts[2]\n",
    "\n",
    "                            # Update word count\n",
    "                            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "                            # Convert sample points to seconds (assuming 16000 Hz sample rate)\n",
    "                            start_sec = max(0, start_sample / 16000 - 0.05)  # 50ms padding before\n",
    "                            end_sec = end_sample / 16000 + 0.05  # 50ms padding after\n",
    "\n",
    "                            # Fetch total duration to avoid exceeding limits\n",
    "                            try:\n",
    "                                result = subprocess.run(['sox', '--i', '-D', wav_file], text=True, capture_output=True, check=True)\n",
    "                                total_duration_sec = float(result.stdout.strip())\n",
    "                                end_sec = min(end_sec, total_duration_sec)  # Ensure end_sec doesn't exceed audio length\n",
    "                            except subprocess.CalledProcessError:\n",
    "                                print(f\"Error retrieving duration for {wav_file}\")\n",
    "                                continue\n",
    "\n",
    "                            # Construct the output file path\n",
    "                            folder_name = os.path.basename(os.path.dirname(wav_file))\n",
    "                            output_filename = f\"{word}_{folder_name}_{os.path.basename(wav_file)}\"\n",
    "                            output_path = os.path.join(output_audio_dir, output_filename)\n",
    "\n",
    "                            # Extract the audio clip using SoX\n",
    "                            command = ['sox', wav_file, output_path, 'trim', str(start_sec), str(end_sec - start_sec)]\n",
    "                            try:\n",
    "                                subprocess.run(command, check=True)\n",
    "                                print(f\"Extracted: {output_path}\")\n",
    "                            except subprocess.CalledProcessError:\n",
    "                                print(f\"Failed to extract audio segment for {word} in {wav_file}\")\n",
    "\n",
    "# Convert word frequency counts to a DataFrame and save as CSV\n",
    "word_count_df = pd.DataFrame(list(word_counts.items()), columns=[\"Word\", \"Count\"])\n",
    "word_count_df.to_csv(os.path.join(root_dir, \"word_frequencies.csv\"), index=False)\n",
    "\n",
    "print(\"Processing complete. Extracted all words with 50ms padding and saved word frequencies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis scipt can loop through all of the TIMIT dataset and generate the clean word excerpts\n",
    "# this can create more than 33,000 clips\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Define directories\n",
    "source_dir = r\"D:\\DNN\\Training_data\\TIMIT\\Extracted_Clips_all_words\"\n",
    "destination_dir = r\"D:\\DNN\\Training_data\\TIMIT\\Extracted_Clips_training\"\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Load the word frequencies CSV\n",
    "csv_path = r\"D:\\DNN\\Training_data\\TIMIT\\word_frequencies.csv\"  # Update if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract words that are **4 or more characters long**\n",
    "df_filtered = df[df[\"Word\"].str.len() >= 4]  # Changed to `>= 4`\n",
    "\n",
    "# Move corresponding files\n",
    "moved_files = []\n",
    "for word in df_filtered[\"Word\"]:\n",
    "    for file in os.listdir(source_dir):\n",
    "        if file.startswith(word + \"_\"):  # Match extracted audio files\n",
    "            src_path = os.path.join(source_dir, file)\n",
    "            dst_path = os.path.join(destination_dir, file)\n",
    "            shutil.move(src_path, dst_path)\n",
    "            moved_files.append(file)\n",
    "\n",
    "print(f\"Moved {len(moved_files)} files to {destination_dir}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
